"""
Creator: Conner Carnahan
Company: GeoOptics
Script Name: netCDF4Utils.py
Creation Date: 12/17/2019
Last Updated: 2/25/2019 by Conner Carnahan
Description: Various scripts for dealing with netCDF4 files to make them more usable in python environments
Dependencies: python, os, netCDF4, numpy, pandas, sys, matplotlib.pyplot
Disclaimer: THIS CODE IS PROVIDED AS IS WITH NO GUARENTEES OF STABLE USAGE.
"""

import os
import netCDF4 as net
import numpy as np
import pandas as pd
import sys
import matplotlib.pyplot as plt
np.set_printoptions(threshold=sys.maxsize)

DEFAULT_VARIABLES = ['occ_id','start_time','lat','lon','overall_qual','snr_L2p','bangle','impact','impact_opt','refrac',
                     'alt_refrac','geop_refrac','undulation','r_coc','roc']

def mergeNetCDF4Directory(directoryName, fileBeginning, outputFileName, separator = '|', variables = DEFAULT_VARIABLES):
    """ mergeNetCDF4Directory(string: directoryName, string: fileBeginning, string: outputFileName,
                              character: separator = '|', array of strings: variables = DEFAULT_VARIABLES):
        This function takes netCDF4 files in a directory with a certain fileBeginning and will merge them into a pandas dataframe
        this dataframe is then printed into a csv and will return the dataframe
        
        The reason for this function: 
        When using ropp to post process occultations it outputs a file that is unwieldy and terrible, additionally it will only be one
        occultation at a time.
        Pandas dataframes are much more user friendly and work with way more packages, so it is nicer to just have all the data in
        that form.
        Also, it is far more useful to have all of the occultations in one bin so they can be analyzed together.

        Things to note:
        Data should be indexed by occultation id by default 
        use something like this to select the row:
            df.loc[df['occ_id'] == id]
        Data is stored in an array of one array for each column (this is the easiest way to store data), 
        so to use the array in any meaningful way you should add a [0] at the end of when you access it.
    """

    pandadata = pd.DataFrame()
    
    for filename in os.listdir(directoryName) :
        if filename.startswith(fileBeginning) :
            print(directoryName + "/" + filename)
            pandadata = pandadata.append(getVariables(net.Dataset(directoryName + "/" + filename), pandadata, variables),
                                         ignore_index = True)
    
    pandadata.to_csv(path_or_buf=outputFileName, sep = '|')
    
    return pandadata

def getVariables(dat, datframe, variables):
    """ getVariables (netCDF4 Dataset: dat, Pandas DataFrame: datframe, array of strings: variables) :
        this is a helper function for mergeNetCDF4Directory
        it converts a single dataset into a pandas dataframe column
    """
    tempData = pd.DataFrame()
    for s in variables :
        try :
            if s == 'occ_id':
                w = ""
                for l in dat.variables[s][:][0]:
                    if l != '--':
                        w += (l.decode('utf-8'))
                tempData[s] = [w]
            else :
                temparray = np.array(dat.variables[s][:][0])
                temparray[temparray=='--'] = np.nan
                tempData[s] = [temparray]
        except KeyError:
            print("Something went wrong (a dataset is either corrupted or didn't process right) \n skipping this dataset")
            return
    return tempData
    
def ReadMergedCSV(fname, datframe):
    """ ReadMergedCSV(string fname, pandas dataframe datframe):
        This will read the csv file created by mergeNetCDF4Directory and overwrite datframe with the values
        Returns: datframe
        Notes: 
        It is a little computationally expensive, since it has to parse a bunch of strings to floats for every occultation
        and perhaps there is a way around this but currently I am not optimizing, just getting things to work
        
        This 100% should not be considered stable for anything other than the files generated by mergeNetCDF4Directory
        
        If we add new variables we want to consider this might also need to be tweeked based on their value types, ect.
    """
    mergeData = pd.read_csv(fname,sep='|')
    mergeData = mergeData.loc[:, ~mergeData.columns.str.contains('^Unnamed')]
    for s in mergeData.columns:
        print("Converting Columns: " + s)
        if s != 'occ_id' and isinstance(mergeData[s][0], str):
            for i in np.arange(len(mergeData.index)):
                temp = np.array(mergeData[s][i].replace('\n','')[1:-1].split(' '))
                temp = temp[temp != '']
                temp = temp.astype(np.float)
                mergeData[s][i]=temp
    datframe = mergeData
    return mergeData

def plotslopeoflnrefrac(datframe):
    """ plotslopeoflnrefrac(pandas dataframe):
        The refractivity as a function of geopotential is approximately e^(at), so this approximates a for each occultation and then
        plots it vs latitude and longitude
    """

    dlnft = np.zeros(len(datframe.index))
    lat = datframe.lat[:]
    lon = datframe.lon[:]
    for i in np.arange(len(datframe.index)):
        dlnft[i] = np.average(dlnf(datframe.refrac[i],datframe.geop_refrac[i]))
    
    fig = plt.figure(figsize=(12,10))
    a = plt.axes()
    a.plot(lat,dlnft,'b.')
    plt.xlabel("latitude")
    plt.ylabel("average change in ln(refrac)")
    plt.show()
    
    fig = plt.figure(figsize=(12,10))
    a = plt.axes()
    plt.xlabel("longitude")
    plt.ylabel("average change in ln(refrac)")
    a.plot(lon,dlnft,'b.')
    plt.show()

def da(a):
    """ da(numpy array of floats a)
        This returns an array that is the change in an array a
    """
    dat = np.zeros(len(a)-1)
    for i in np.arange(len(a)-1):
        dat[i] = a[i+1]-a[i]
    return dat

def dlnf(f,t):
    """ dlnf(numpy array f, numpy array t):
        approximates the value of the derivative of the natural log of a variable with respect to t, given a linear relationship.
    """
    dln = np.zeros(len(f)-1)
    for i in np.arange(len(f)-2):
        dln[i] = np.divide(f[i+2]-f[i],f[i+1]*(t[i+2]-t[i]))
    return dln

def plotbindataaverage(datframe, xname, yname, minx, maxx, binsize, ubound = np.inf, lbound = -np.inf, minsnr = 0):
    """ plotbindataverage(datframe pandas dataframe, xname string, yname string, minx float, maxx float, binsize = float, ubound = np.inf, lbound = -np.inf, minsnr = 0):
        This plots the average values of binned data, minx should be < maxx, binsize should be positive
        xname is the name of the xvariable, yname is the yvariable
        datframe is the dataframe that holds the data
        ubound and lbound are the upper and lower bounds respectively on what data is averaged for the y values (this is for minimizing artifacts in data)
        minsnr is the minimum value that the avgsnr_L2p variable can have for the graphed data
    """
    xbins = np.linspace(minx,maxx,num = (int)((maxx-minx)/binsize))
    ybins = np.zeros(len(xbins))
    ybins[0] = np.average(datframe[yname][(datframe[xname] < xbins[1])
                                          & (datframe[yname] > lbound)
                                          & (datframe[yname] < ubound)
                                          & (datframe['avgsnr_L2p'] > minsnr)])
    
    for i in np.arange(len(xbins)-2):
        ybins[i+1] = np.average(datframe[yname][(datframe[xname] < xbins[i+2]) 
                                                & (datframe[xname] > xbins[i]) 
                                                & (datframe[yname] > lbound)
                                                & (datframe[yname] < ubound)
                                                & (datframe['avgsnr_L2p'] > minsnr)])
        
    ybins[len(ybins)-1] = np.average(datframe[yname][(datframe[xname] > xbins[len(ybins)-2])
                                                    & (datframe[yname] > lbound)
                                                    & (datframe[yname] < ubound)
                                                    & (datframe['avgsnr_L2p'] > minsnr)])
    
    fig = plt.figure(figsize=(12,10))
    a = plt.axes()
    a.plot(xbins,ybins,'b.-')
    plt.xlabel(xname)
    plt.ylabel(yname)
    plt.show()

def plotnuminbin(datframe, xname, minx, maxx, binsize): 
    """ plotnuminbin(pandas dataframe datframe, string xname, float minx, float maxx, float binsize):
        This plots the number of rows that are put into bins based on their values for the variable xname.
        minx sets the minimum of the graph
        maxx sets the maximum
        binsize sets the size of the bins
    """
    xbins = np.linspace(minx,maxx,num = (int)((maxx-minx)/binsize))
    ybins = np.zeros(len(xbins))
    
    ybins[0] = np.size(datframe.index[(datframe[xname] < xbins[1])])
    
    for i in np.arange(len(xbins)-2):
        ybins[i+1] = np.size(datframe.index[(datframe[xname] < xbins[i+2]) 
                                                & (datframe[xname] > xbins[i])])
        
    ybins[len(ybins)-1] = np.size(datframe.index[(datframe[xname] > xbins[len(ybins)-2])])
    
    fig = plt.figure(figsize=(12,10))
    a = plt.axes()
    a.plot(xbins,ybins,'b.-')
    plt.xlabel(xname)
    plt.ylabel('Num')
    plt.show()


def plotscrubdataverage(datframe, xname, yname, minx, maxx, scrubsize,ubound = np.inf, lbound = -np.inf,
                        minsnr = 0, num = 100):
    """plotscrubdataverage(pandas dataframe datfame, string xname, string yname, float minx, float maxx, array of floats scrubsize,
                           float ubound = np.inf, float lbound = -np.inf, minsnr = 0, num = 100)
    """
    fig = plt.figure(figsize=(12,10))
    a = plt.axes()
    
    for x in scrubsize:
        xlefts = np.linspace(minx,maxx,num)
        xrights = xlefts + x
        ybins = np.zeros(num)
        for i in np.arange(num):
            ybins[i] = np.average(datframe[yname][(datframe[xname] > xlefts[i]) 
                                                 & (datframe[xname] < xrights[i])
                                                 & (datframe[yname] < ubound)
                                                 & (datframe[yname] > lbound)
                                                 & (datframe['avgsnr_L2p'] > minsnr)]) 
        a.plot(xlefts + x/2,ybins, label = 'Scrub Size: ' + str(x))
    
    plt.xlabel(xname)
    plt.ylabel(yname)
    plt.show()



def appenddlnvar(datframe, varname, tname, lbound, ubound):
    """ appenddlnvar(pandas dataframe datfame, string varname, string tname, float lbound, float ubound):
        This appends the value of the derivative of a natural log of a variable with respect to t.
        It then averages this over the column array and will only average values between lbound and ubound
    """
    dln = np.zeros(len(datframe.index))
    for i in np.arange(len(datframe.index)):
        dln2 = dlnf(datframe[varname][i],datframe[tname][i])
        dln[i] = np.average(dln2[(dln2>lbound)&(dln2<ubound)])
    datframe.insert(len(datframe.columns),'dln' + varname, dln)

def appendAvg(datframe, varname):
    """ appendlnvar(datframe pandas dataframe, varname string, ttname string):
        appends the average of an array entry in a specific row to the row
        returns none
    """
    avg = np.zeros(len(datframe.index))
    for i in np.arange(len(datframe.index)):
        avg[i] = np.average(datframe[varname][i])
    return datframe.insert(len(datframe.columns),'avg'+varname,avg)

def PlotRowArrays(datframe, fname, tname, index, showids = False):
    """ PlotRowArrays(pdataframe datframe, string fname, string tname, array of indeces index, showids = False):
        This plots the values of each row's fname column vs its tname for each row in index.
        On the plot you can specify if you want the occultation id to be labeled on the graph
    """
    fig = plt.figure(figsize=(12,10))
    a = plt.axes()
    for i in index:
        a.plot(datframe.geop_refrac[i],datframe.refrac[i], label = datframe.occ_id[i])
    plt.xlabel(tname)
    plt.ylabel(fname)
    if showids:
        plt.legend()
    plt.show()

def AppendFunc(datframe, fname, func, funcname):
    """ AppendFunc(pandas dataframe datframe, string fname, function func, string funcname):
        The purpose of this is to append a value to a dataframe based on the value of a function of one of the columns of the dataframe.
        For example: if I wanted to add an average of an array in a certain column for each row then I would apply this with np.average in the func spot
        datframe is the dataframe you want to append
        fname is the name of the variable
        func is a function you want to apply to the fname variable
        funcname is the name you want for the new column (it will end up being funcname'_'fname)
    """
    b = np.zeros(len(datframe.index))
    for i in datframe.index:
        b[i] = func(datframe[fname][i])
    datframe.insert(len(datframe.columns),funcname + '_' +  fname, b)


#def cleanData(datframe):
